# ğŸŒ Web Crawler (Python)

Un petit crawler web Ã©crit en Python. Il explore une URL de dÃ©part, visite plusieurs pages, extrait tous les liens HTML (`<a href="...">`) valides, et les enregistre automatiquement dans un fichier texte datÃ©.

---

## ğŸš€ FonctionnalitÃ©s

âœ… Exploration rÃ©cursive Ã  partir d'une URL  
âœ… Extraction de tous les liens HTTP/HTTPS  
âœ… Limite du nombre de pages Ã  visiter  
âœ… Sauvegarde des liens dans un fichier `.txt` avec date/heure  
âœ… Pause automatique entre chaque requÃªte pour Ã©viter la surcharge du serveur  

---

## ğŸ“ Arborescence du projet

```
web-crawler/
â”œâ”€â”€ crawler.py           # Script principal
â”œâ”€â”€ run_crawler.bat      # Lancement rapide (Windows)
â”œâ”€â”€ requirements.txt     # DÃ©pendances Python
â”œâ”€â”€ .gitignore           # Fichiers Ã  ignorer dans Git
â””â”€â”€ README.md            # Ce fichier
```

---

## ğŸ“¦ Installation

1. **Clone le dÃ©pÃ´t** :

```bash
git clone https://github.com/PariaHRZ/web-crawler.git
cd web-crawler
```

2. **Installe les dÃ©pendances** :

```bash
pip install -r requirements.txt
```

---

## ğŸ› ï¸ Utilisation

### ğŸ En ligne de commande

```bash
python crawler.py
```

### ğŸ–±ï¸ Sur Windows

Double-clique sur le fichier `run_crawler.bat`.

---

## âš™ï¸ Personnalisation

Dans `crawler.py`, tu peux modifier ces deux lignes :

```python
seed_url = "https://example.com"  # URL de dÃ©part
links = crawl(seed_url, max_pages=20)  # Nombre de pages Ã  visiter
```

---

## ğŸ“ RÃ©sultat

Le script crÃ©e automatiquement un dossier `output/` et y enregistre un fichier texte nommÃ© par date et heure, exemple :

```
output/crawled_links_12-05-2025_15-42-07.txt
```

Chaque ligne du fichier correspond Ã  un lien trouvÃ© pendant le crawling.

---

## âš ï¸ Avertissement

> âš ï¸ Utilise ce crawler uniquement sur des sites que tu es autorisÃ© Ã  explorer.  
> Respecte les conditions d'utilisation et les fichiers `robots.txt` des sites web.

---

## ğŸ“œ Licence

Ce projet est sous **[licence MIT](https://github.com/PariaHRZ/web-crawler/blob/main/LICENSE)**.  
Tu peux l'utiliser, le modifier et le partager librement.

---

## ğŸ‘¤ Auteur

DÃ©veloppÃ© par **[PariaHRZ](https://github.com/PariaHRZ)**  
